{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "335a032b630676e775efc24be66b729b6ef649829e6fe66a2743eab08cde9faf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import pickle \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-a2a7a3113729>:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  aita['title_body_combo'] =  aita_2['title_clean'] + aita_2['body_clean']\n"
     ]
    }
   ],
   "source": [
    "aita_2 = pd.read_csv('data/aita_save2.csv')\n",
    "aita_2.dropna(subset=['body_clean', 'title_clean'], inplace=True)\n",
    "\n",
    "aita = aita_2[['body_polarity','body_subjectivity','is_asshole']]\n",
    "aita['title_body_combo'] =  aita_2['title_clean'] + aita_2['body_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       body_polarity  body_subjectivity  is_asshole  \\\n",
       "0          -0.156818           0.656818           1   \n",
       "1           0.034848           0.449242           1   \n",
       "2           0.000000           0.000000           0   \n",
       "3           0.000000           0.000000           1   \n",
       "4           0.040104           0.369792           1   \n",
       "...              ...                ...         ...   \n",
       "97536       0.016111           0.385278           0   \n",
       "97537       0.068461           0.474614           0   \n",
       "97538      -0.076333           0.493467           0   \n",
       "97539       0.067130           0.426132           0   \n",
       "97540      -0.007238           0.524378           0   \n",
       "\n",
       "                                        title_body_combo  \n",
       "0        I write an explanation in til and come off a...  \n",
       "1        throw my parent donut awaymy parent be diabe...  \n",
       "2      I tell a goth girl she look like a clownI be four  \n",
       "3        argument I have with another redditor in rhi...  \n",
       "4        have a disagreement about le miserable with ...  \n",
       "...                                                  ...  \n",
       "97536    for tell my sister she be be a spoiled bratm...  \n",
       "97537    for tell my husband to f off after he relent...  \n",
       "97538    for attempt to keep my student out of adult ...  \n",
       "97539    if I leave my brother fate up to the statea ...  \n",
       "97540    for rock the boat at work because my mentor ...  \n",
       "\n",
       "[97455 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body_polarity</th>\n      <th>body_subjectivity</th>\n      <th>is_asshole</th>\n      <th>title_body_combo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.156818</td>\n      <td>0.656818</td>\n      <td>1</td>\n      <td>I write an explanation in til and come off a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.034848</td>\n      <td>0.449242</td>\n      <td>1</td>\n      <td>throw my parent donut awaymy parent be diabe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>I tell a goth girl she look like a clownI be four</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>argument I have with another redditor in rhi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.040104</td>\n      <td>0.369792</td>\n      <td>1</td>\n      <td>have a disagreement about le miserable with ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97536</th>\n      <td>0.016111</td>\n      <td>0.385278</td>\n      <td>0</td>\n      <td>for tell my sister she be be a spoiled bratm...</td>\n    </tr>\n    <tr>\n      <th>97537</th>\n      <td>0.068461</td>\n      <td>0.474614</td>\n      <td>0</td>\n      <td>for tell my husband to f off after he relent...</td>\n    </tr>\n    <tr>\n      <th>97538</th>\n      <td>-0.076333</td>\n      <td>0.493467</td>\n      <td>0</td>\n      <td>for attempt to keep my student out of adult ...</td>\n    </tr>\n    <tr>\n      <th>97539</th>\n      <td>0.067130</td>\n      <td>0.426132</td>\n      <td>0</td>\n      <td>if I leave my brother fate up to the statea ...</td>\n    </tr>\n    <tr>\n      <th>97540</th>\n      <td>-0.007238</td>\n      <td>0.524378</td>\n      <td>0</td>\n      <td>for rock the boat at work because my mentor ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>97455 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "aita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = aita.drop('is_asshole', axis=1)\n",
    "y = aita['is_asshole']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.01, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((96480, 3), (975, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "## Instantiate CountVectorizer "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = set(stopwords.words('english'))\n",
    "# vec = CountVectorizer(stop_words=stop, min_df=50, max_df=0.8, ngram_range=(1, 3))\n",
    "# cv = vec.fit(X_train['title_body_combo'])"
   ]
  },
  {
   "source": [
    "### Save fitted CountVectorizer to use later"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "44051"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "# pickle.dump(cv, open('models/cv_fit_train.sav', 'wb'))\n",
    "# len(vec.get_feature_names())"
   ]
  },
  {
   "source": [
    "### Load fitted CountVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load(open('models/cv_fit_train.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = cv.transform(X_train['title_body_combo'])\n",
    "cv_test = cv.transform(X_test['title_body_combo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "get       228922\n",
       "go        198113\n",
       "say       197408\n",
       "tell      169258\n",
       "would     165609\n",
       "want      159291\n",
       "like      139417\n",
       "friend    132208\n",
       "time      122214\n",
       "know      108087\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "dtm_train = pd.DataFrame(cv_train.toarray(), columns=cv.get_feature_names())\n",
    "train_word_count = dtm_train.sum(axis=0)\n",
    "train_word_count.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "get       2354\n",
       "say       1991\n",
       "go        1967\n",
       "tell      1704\n",
       "want      1680\n",
       "would     1608\n",
       "like      1352\n",
       "friend    1291\n",
       "time      1262\n",
       "know      1147\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "dtm_test = pd.DataFrame(cv_test.toarray(), columns=cv.get_feature_names())\n",
    "test_word_count = dtm_test.sum(axis=0)\n",
    "test_word_count.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((96480, 44051), (975, 44051))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "dtm_train.shape, dtm_test.shape"
   ]
  },
  {
   "source": [
    "### Save / Load Document Term Matrix to / from csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtm_train.to_csv('data/dtm_train.csv', index=False)\n",
    "# dtm_test.to_csv('data/dtm_test.csv', index=False)\n",
    "\n",
    "dtm_train = pd.read_csv('data/dtm_train.csv')\n",
    "dtm_test = pd.read_csv('data/dtm_test.csv')"
   ]
  },
  {
   "source": [
    "## PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = IncrementalPCA(n_components=800, batch_size=850)\n",
    "pca.fit(dtm_train)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "source": [
    "### Save / Load fitted PCA Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca, open('models/pca.sav', 'wb'))\n",
    "\n",
    "# pca = pickle.load(open('models/pca.sav', 'rb'))\n",
    "# pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.title('PCA Scree Plot')\n",
    "# plt.axvline(linewidth=4, color='r', linestyle = '--', x=10, ymin=0, ymax=1)\n",
    "evr = pca.explained_variance_ratio_\n",
    "cvr = np.cumsum(pca.explained_variance_ratio_)\n",
    "pca_df = pd.DataFrame()\n",
    "pca_df['Cumulative Variance Ratio'] = cvr\n",
    "pca_df['Explained Variance Ratio'] = evr\n",
    "# display(pca_df.head(10))"
   ]
  },
  {
   "source": [
    "### Transform train and test Document-Term-matrix with PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train_pca = pca.transform(dtm_train)\n",
    "dtm_test_pca = pca.transform(dtm_test)"
   ]
  },
  {
   "source": [
    "Build DataFrame of PCA Components"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['PC_' + str(i) for i in range(1, pca.get_params()['n_components']+1)]\n",
    "dtm_train_pca_df = pd.DataFrame(dtm_train_pca, columns=col_names)\n",
    "dtm_test_pca_df = pd.DataFrame(dtm_test_pca, columns=col_names)"
   ]
  },
  {
   "source": [
    "Combine PCA components and sentiment analysis scores into one DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_post_dtm_pca = pd.concat([X_train[['body_polarity','body_subjectivity']].reset_index(drop=True), dtm_train_pca_df], axis=1)\n",
    "X_test_post_dtm_pca = pd.concat([X_test[['body_polarity','body_subjectivity']].reset_index(drop=True),dtm_test_pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   body_polarity  body_subjectivity      PC_1      PC_2      PC_3      PC_4  \\\n",
       "0       0.045523           0.447194 -3.230100 -0.506262 -0.139275  1.216879   \n",
       "1       0.123488           0.487960 -1.699640  2.655335 -3.511593  0.710250   \n",
       "2       0.366667           0.689286 -4.890311  0.851776  0.387777 -0.448441   \n",
       "3       0.111569           0.346238  2.095763 -4.452893 -1.538845  2.611905   \n",
       "4      -0.013474           0.466071 -2.871271  0.770379  3.248285  0.054712   \n",
       "\n",
       "       PC_5      PC_6      PC_7      PC_8  ...    PC_791    PC_792    PC_793  \\\n",
       "0 -0.989355 -0.290268 -0.460918  0.695942  ... -0.305248 -0.081111 -0.228890   \n",
       "1 -1.468153 -0.420901 -0.444954 -0.457874  ...  0.000567 -0.002906 -0.033091   \n",
       "2  0.932522  0.722537  0.917917  0.125428  ...  0.016830  0.018513 -0.056724   \n",
       "3 -3.823879  2.705971 -1.287494 -1.660388  ...  0.128382 -0.090228 -0.156075   \n",
       "4 -1.480608 -0.512396 -0.607933 -0.719146  ... -0.134697 -0.139258  0.085203   \n",
       "\n",
       "     PC_794    PC_795    PC_796    PC_797    PC_798    PC_799    PC_800  \n",
       "0  0.225672 -0.131362 -0.158019 -0.091304  0.118803 -0.142652  0.020049  \n",
       "1 -0.162508 -0.052741  0.321190 -0.363125 -0.091853  0.271374  0.200574  \n",
       "2 -0.201364  0.031839 -0.126647  0.095873  0.089574 -0.006338  0.071553  \n",
       "3  0.595058 -0.078841 -0.040142  0.214096  0.097223 -0.047814  0.137292  \n",
       "4  0.153525 -0.224926  0.189807  0.074606  0.283557  0.327423  0.715444  \n",
       "\n",
       "[5 rows x 802 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body_polarity</th>\n      <th>body_subjectivity</th>\n      <th>PC_1</th>\n      <th>PC_2</th>\n      <th>PC_3</th>\n      <th>PC_4</th>\n      <th>PC_5</th>\n      <th>PC_6</th>\n      <th>PC_7</th>\n      <th>PC_8</th>\n      <th>...</th>\n      <th>PC_791</th>\n      <th>PC_792</th>\n      <th>PC_793</th>\n      <th>PC_794</th>\n      <th>PC_795</th>\n      <th>PC_796</th>\n      <th>PC_797</th>\n      <th>PC_798</th>\n      <th>PC_799</th>\n      <th>PC_800</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.045523</td>\n      <td>0.447194</td>\n      <td>-3.230100</td>\n      <td>-0.506262</td>\n      <td>-0.139275</td>\n      <td>1.216879</td>\n      <td>-0.989355</td>\n      <td>-0.290268</td>\n      <td>-0.460918</td>\n      <td>0.695942</td>\n      <td>...</td>\n      <td>-0.305248</td>\n      <td>-0.081111</td>\n      <td>-0.228890</td>\n      <td>0.225672</td>\n      <td>-0.131362</td>\n      <td>-0.158019</td>\n      <td>-0.091304</td>\n      <td>0.118803</td>\n      <td>-0.142652</td>\n      <td>0.020049</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.123488</td>\n      <td>0.487960</td>\n      <td>-1.699640</td>\n      <td>2.655335</td>\n      <td>-3.511593</td>\n      <td>0.710250</td>\n      <td>-1.468153</td>\n      <td>-0.420901</td>\n      <td>-0.444954</td>\n      <td>-0.457874</td>\n      <td>...</td>\n      <td>0.000567</td>\n      <td>-0.002906</td>\n      <td>-0.033091</td>\n      <td>-0.162508</td>\n      <td>-0.052741</td>\n      <td>0.321190</td>\n      <td>-0.363125</td>\n      <td>-0.091853</td>\n      <td>0.271374</td>\n      <td>0.200574</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.366667</td>\n      <td>0.689286</td>\n      <td>-4.890311</td>\n      <td>0.851776</td>\n      <td>0.387777</td>\n      <td>-0.448441</td>\n      <td>0.932522</td>\n      <td>0.722537</td>\n      <td>0.917917</td>\n      <td>0.125428</td>\n      <td>...</td>\n      <td>0.016830</td>\n      <td>0.018513</td>\n      <td>-0.056724</td>\n      <td>-0.201364</td>\n      <td>0.031839</td>\n      <td>-0.126647</td>\n      <td>0.095873</td>\n      <td>0.089574</td>\n      <td>-0.006338</td>\n      <td>0.071553</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.111569</td>\n      <td>0.346238</td>\n      <td>2.095763</td>\n      <td>-4.452893</td>\n      <td>-1.538845</td>\n      <td>2.611905</td>\n      <td>-3.823879</td>\n      <td>2.705971</td>\n      <td>-1.287494</td>\n      <td>-1.660388</td>\n      <td>...</td>\n      <td>0.128382</td>\n      <td>-0.090228</td>\n      <td>-0.156075</td>\n      <td>0.595058</td>\n      <td>-0.078841</td>\n      <td>-0.040142</td>\n      <td>0.214096</td>\n      <td>0.097223</td>\n      <td>-0.047814</td>\n      <td>0.137292</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.013474</td>\n      <td>0.466071</td>\n      <td>-2.871271</td>\n      <td>0.770379</td>\n      <td>3.248285</td>\n      <td>0.054712</td>\n      <td>-1.480608</td>\n      <td>-0.512396</td>\n      <td>-0.607933</td>\n      <td>-0.719146</td>\n      <td>...</td>\n      <td>-0.134697</td>\n      <td>-0.139258</td>\n      <td>0.085203</td>\n      <td>0.153525</td>\n      <td>-0.224926</td>\n      <td>0.189807</td>\n      <td>0.074606</td>\n      <td>0.283557</td>\n      <td>0.327423</td>\n      <td>0.715444</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 802 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "X_train_post_dtm_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(68218, 802) (68218,)\n(29237, 802) (29237,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_post_dtm_pca.shape, y_train.shape)\n",
    "print(X_test_post_dtm_pca.shape, y_test.shape)"
   ]
  },
  {
   "source": [
    "## Random Forest Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Vanilla Random Forest, no tuning hyperparameters "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_post_dtm_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "rfc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy = {rfc.score(X_train_post_dtm_pca, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing Accuracy = 0.7267161473475391\n"
     ]
    }
   ],
   "source": [
    "print(f'Testing Accuracy = {rfc.score(X_test_post_dtm_pca, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.72708618, 0.72435021, 0.72601334, 0.72721054, 0.72618437])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "cross_val_score(rfc, X_test_post_dtm_pca, y_test, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}